{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "driver_action_detection.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cathay/cnn/blob/master/driver_action_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66oV53yGuSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "b3efe67f-6f3c-4cd8-d84e-27367e49c215"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from shutil import copyfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Import Google drive functions\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9zNaONpaNHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Authorize Google drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#download train and test images\n",
        "#download = drive.CreateFile({'id': '1KPoJecKIQCufzJo-LANkySjF8rp4motV'})\n",
        "#download.GetContentFile('driver-detection-train-data.zip')\n",
        "\n",
        "#download = drive.CreateFile({'id': '1POWy7luJLkVWEo5Iq0Dkgj1EbGn81-RQ'})\n",
        "#download.GetContentFile('driver-detection-\btest-data.zip')\n",
        "\n",
        "#Extract files\n",
        "#zip_ref = zipfile.ZipFile('driver-detection-train-data.zip', 'r')\n",
        "#zip_ref.extractall('tmp/trains')\n",
        "import fnmatch\n",
        "\n",
        "##Not sure why it cannot detect the file\n",
        "for file in os.listdir('.'):\n",
        "    if fnmatch.fnmatch(file, '*test*.zip'):\n",
        "        zip_ref = zipfile.ZipFile(file, 'r')\n",
        "        zip_ref.extractall('tmp/test')\n",
        "\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1JGBTxw-2IZ",
        "colab_type": "code",
        "outputId": "d954fcb3-cefe-4034-cbb6-4b19fe80fb85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "def get_im_cv2(path, w, h):\n",
        "  img = cv2.imread(path)\n",
        "  resized = cv2.resize(img, (w,h), cv2.INTER_LINEAR) \n",
        "  return resized\n",
        "\n",
        "TRAINING_DIR = 'tmp/trains/driver-detection-train-data'\n",
        "IMAGE_WIDTH=224\n",
        "IMAGE_HEIGHT=224\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "\n",
        "files = []\n",
        "categories = []\n",
        "paths = []\n",
        "\n",
        "for i in range(10):\n",
        "  for file in os.listdir(\"%s/c%s\" %(TRAINING_DIR, i)):\n",
        "    files.append(file)\n",
        "    categories.append(i)\n",
        "    paths.append(\"%s/c%s/%s\" %(TRAINING_DIR, i, file))\n",
        "\n",
        "df = pd.DataFrame({'file': files,\n",
        "                   'category': categories,\n",
        "                   'path': paths\n",
        "                  })\n",
        "\n",
        "df['Y'] = df['category'].map(lambda x: to_categorical(x, 10, dtype='uint8'))\n",
        "df['X'] = df['path'].map(lambda path: get_im_cv2(path, IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "df.sample(5, axis=None)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>category</th>\n",
              "      <th>path</th>\n",
              "      <th>Y</th>\n",
              "      <th>X</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3943</th>\n",
              "      <td>img_21191.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>tmp/trains/driver-detection-train-data/c1/img_...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[[[10, 17, 10], [9, 16, 9], [8, 15, 8], [9, 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7870</th>\n",
              "      <td>img_53391.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>tmp/trains/driver-detection-train-data/c3/img_...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[[[9, 14, 12], [9, 14, 12], [9, 14, 12], [11, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19493</th>\n",
              "      <td>img_92021.jpg</td>\n",
              "      <td>8</td>\n",
              "      <td>tmp/trains/driver-detection-train-data/c8/img_...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[[[46, 53, 46], [45, 52, 45], [44, 51, 44], [4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16793</th>\n",
              "      <td>img_60726.jpg</td>\n",
              "      <td>7</td>\n",
              "      <td>tmp/trains/driver-detection-train-data/c7/img_...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[[[31, 41, 35], [29, 39, 32], [31, 42, 32], [3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2577</th>\n",
              "      <td>img_56169.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>tmp/trains/driver-detection-train-data/c1/img_...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[[[34, 42, 35], [29, 38, 31], [28, 36, 29], [2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                file  ...                                                  X\n",
              "3943   img_21191.jpg  ...  [[[10, 17, 10], [9, 16, 9], [8, 15, 8], [9, 16...\n",
              "7870   img_53391.jpg  ...  [[[9, 14, 12], [9, 14, 12], [9, 14, 12], [11, ...\n",
              "19493  img_92021.jpg  ...  [[[46, 53, 46], [45, 52, 45], [44, 51, 44], [4...\n",
              "16793  img_60726.jpg  ...  [[[31, 41, 35], [29, 39, 32], [31, 42, 32], [3...\n",
              "2577   img_56169.jpg  ...  [[[34, 42, 35], [29, 38, 31], [28, 36, 29], [2...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYd6MSDzF9mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "\n",
        "x_train = []\n",
        "x_test = []\n",
        "y_train = []\n",
        "y_test= []\n",
        "\n",
        "for item in train_df['X']:\n",
        "  x_train.append(item)\n",
        "\n",
        "for item in validate_df['X']:\n",
        "  x_test.append(item)\n",
        "\n",
        "for item in train_df['Y']:\n",
        "  y_train.append(item)\n",
        "\n",
        "for item in validate_df['Y']:\n",
        "  y_test.append(item)\n",
        "\n",
        "x_train = np.array(x_train, dtype=np.uint8)\n",
        "x_test = np.array(x_test, dtype=np.uint8)\n",
        "y_train = np.array(y_train, dtype=np.uint8)\n",
        "y_test = np.array(y_test, dtype=np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viyBcqVFGGK1",
        "colab_type": "code",
        "outputId": "874f4149-a610-46db-df7b-091172b91215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#build model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "#base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax')) # \n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0001), metrics=['accuracy'])\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "## Train\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "earlystop = EarlyStopping(patience=5)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.0001)\n",
        "EPOCHS=10\n",
        "BATCH_SIZE=15\n",
        "callbacks = [learning_rate_reduction]\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train,\n",
        "                    shuffle=True,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test)\n",
        "                    ,callbacks=callbacks)\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 3s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              102761472 \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 126,885,258\n",
            "Trainable params: 103,294,474\n",
            "Non-trainable params: 23,590,784\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 17939 samples, validate on 4485 samples\n",
            "Epoch 1/20\n",
            "17939/17939 [==============================] - 97s 5ms/step - loss: 0.8423 - acc: 0.7449 - val_loss: 0.1135 - val_acc: 0.9875\n",
            "Epoch 2/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.2370 - acc: 0.9466 - val_loss: 0.0539 - val_acc: 0.9933\n",
            "Epoch 3/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.1470 - acc: 0.9700 - val_loss: 0.0368 - val_acc: 0.9949\n",
            "Epoch 4/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.1082 - acc: 0.9790 - val_loss: 0.0275 - val_acc: 0.9964\n",
            "Epoch 5/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0824 - acc: 0.9847 - val_loss: 0.0222 - val_acc: 0.9967\n",
            "Epoch 6/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0714 - acc: 0.9868 - val_loss: 0.0196 - val_acc: 0.9967\n",
            "Epoch 7/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0566 - acc: 0.9906 - val_loss: 0.0165 - val_acc: 0.9969\n",
            "Epoch 8/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0470 - acc: 0.9925 - val_loss: 0.0146 - val_acc: 0.9969\n",
            "Epoch 9/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0439 - acc: 0.9923 - val_loss: 0.0137 - val_acc: 0.9978\n",
            "Epoch 10/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0388 - acc: 0.9938 - val_loss: 0.0124 - val_acc: 0.9975\n",
            "Epoch 11/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0350 - acc: 0.9950 - val_loss: 0.0119 - val_acc: 0.9978\n",
            "Epoch 12/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0314 - acc: 0.9953 - val_loss: 0.0109 - val_acc: 0.9975\n",
            "Epoch 13/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0291 - acc: 0.9951 - val_loss: 0.0105 - val_acc: 0.9978\n",
            "Epoch 14/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0277 - acc: 0.9958 - val_loss: 0.0096 - val_acc: 0.9980\n",
            "Epoch 15/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0256 - acc: 0.9965 - val_loss: 0.0091 - val_acc: 0.9978\n",
            "Epoch 16/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0220 - acc: 0.9971 - val_loss: 0.0089 - val_acc: 0.9980\n",
            "Epoch 17/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0203 - acc: 0.9978 - val_loss: 0.0088 - val_acc: 0.9982\n",
            "Epoch 18/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0208 - acc: 0.9972 - val_loss: 0.0085 - val_acc: 0.9978\n",
            "Epoch 19/20\n",
            "17939/17939 [==============================] - 82s 5ms/step - loss: 0.0176 - acc: 0.9978 - val_loss: 0.0084 - val_acc: 0.9980\n",
            "Epoch 20/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0192 - acc: 0.9974 - val_loss: 0.0081 - val_acc: 0.9980\n",
            "Test loss: 0.008133853698090143\n",
            "Test accuracy: 0.9979933110367893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX47V4P2hyuN",
        "colab_type": "code",
        "outputId": "4c1fc413-db28-49f6-9f9b-55295e84331a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "TEST_DIRECTORY = 'tmp/test/driver-detection-test-data/batch0'\n",
        "test_data = pd.DataFrame({'filename': os.listdir(TEST_DIRECTORY)})\n",
        "\n",
        "test_data_frame = test_data.sample(20, axis=None)\n",
        "test_data_frame['X'] = test_data_frame['filename'].map(lambda file: get_im_cv2(TEST_DIRECTORY + \"/\" + file, IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "\n",
        "x_perf=[]\n",
        "for item in test_data_frame['X']:\n",
        "  x_perf.append(item)\n",
        "\n",
        "x_perf = np.array(x_perf, dtype=np.uint8)\n",
        "predict = model.predict(x_perf)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a97f896e5ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp/imgs/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTEST_DIRECTORY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tmp/test/driver-detection-test-data/batch0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DIRECTORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_data_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/imgs/test'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hoo96YXujqxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot prediction\n",
        "import matplotlib.pyplot as plt\n",
        "label_map = {\n",
        "    0: \"normal driving\",\n",
        "    1: \"texting - right\",\n",
        "    2: \"talking on the phone - right\",\n",
        "    3: \"texting - left\",\n",
        "    4: \"talking on the phone - left\",\n",
        "    5: \"operating the radio\",\n",
        "    6: \"drinking\",\n",
        "    7: \"reaching behind\",\n",
        "    8: \"hair and makeup\",\n",
        "    9: \"talking to passenger\"\n",
        "}\n",
        "\n",
        "test_data_frame['category'] = np.argmax(predict, axis=1)\n",
        "test_data_frame['action'] = test_data_frame['category'].map(lambda x: label_map.get(x))\n",
        "print(test_data_frame.head())\n",
        "\n",
        "#Draw predictions with images\n",
        "from keras.preprocessing.image import load_img\n",
        "sample_test = test_data_frame\n",
        "plt.figure(figsize=(12, 24))\n",
        "index=0\n",
        "for _, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['action']\n",
        "    index=index+1\n",
        "    img = load_img(TEST_DIRECTORY+filename, target_size=IMAGE_SIZE)\n",
        "    plt.subplot(6, 3, index)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtk8tf_IBo7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}