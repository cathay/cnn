{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolo.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cathay/cnn/blob/master/yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66oV53yGuSX",
        "colab_type": "code",
        "outputId": "288b5ae0-f7c7-49ef-98f7-b239c0250d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from shutil import copyfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xLJfNzlOphf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "06282a95-e5d5-4983-d678-6fb0fcea3cc5"
      },
      "source": [
        "from functools import reduce\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "def compose(*funcs):\n",
        "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
        "    Reference: https://mathieularose.com/function-composition-in-python/\n",
        "    \"\"\"\n",
        "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
        "    if funcs:\n",
        "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
        "    else:\n",
        "        raise ValueError('Composition of empty sequence not supported.')\n",
        "\n",
        "#build YOLO model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "IMAGE_WIDTH=448\n",
        "IMAGE_HEIGHT=448\n",
        "IMAGE_CHANNELS=3\n",
        "\n",
        "class Yolo(object):\n",
        "    def __init__(self, training=True, num_classes=21, weights=None):\n",
        "        '''\n",
        "        Fast RCNN introduced in Faster R-CNN.\n",
        "        '''\n",
        "        super(Yolo, self).__init__()\n",
        "\n",
        "        self.training = training\n",
        "        self.num_classes = num_classes\n",
        "        self.model = Sequential()\n",
        "\n",
        "        self.buildModel()\n",
        "\n",
        "\n",
        "    def Conv2D(self, *args, **kwargs):\n",
        "        \"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"\n",
        "        _kwargs = {'kernel_regularizer': l2(5e-4)}\n",
        "        _kwargs['padding'] = 'valid' if kwargs.get('strides') == (2, 2) else 'same'\n",
        "        _kwargs.update(kwargs)\n",
        "        return Conv2D(*args, **_kwargs)\n",
        "\n",
        "    def Conv2D_BN_Leaky(self, *args, **kwargs):\n",
        "        \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
        "        no_bias_kwargs = {'use_bias': False}\n",
        "        no_bias_kwargs.update(kwargs)\n",
        "        self.model.add(Conv2D(*args, **no_bias_kwargs))\n",
        "        self.model.add(BatchNormalization())\n",
        "        self.model.add(LeakyReLU(alpha=0.1))\n",
        "    \n",
        "    def maxPooling(self):\n",
        "      self.model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n",
        "\n",
        "    def buildModel(self):\n",
        "      self.Conv2D_BN_Leaky(64, (7, 7), strides=2, padding='same', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "      self.maxPooling()\n",
        "\n",
        "      self.Conv2D_BN_Leaky(192, (3, 3), strides=2, padding='same')\n",
        "      self.maxPooling()\n",
        "    \n",
        "    def summary(self):\n",
        "      self.model.summary()  \n",
        "\n",
        "yolo = Yolo(num_classes=30)\n",
        "yolo.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_230 (Conv2D)          (None, 224, 224, 64)      9408      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 224, 224, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 224, 224, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_62 (MaxPooling (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_231 (Conv2D)          (None, 56, 56, 192)       110592    \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 56, 56, 192)       768       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 56, 56, 192)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_63 (MaxPooling (None, 28, 28, 192)       0         \n",
            "=================================================================\n",
            "Total params: 121,024\n",
            "Trainable params: 120,512\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRNf8egLBoUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "6af20b46-0e19-407c-9b3f-ff95f3659bce"
      },
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "Conv2D_BN_Leaky(64, (7, 7), strides=2, padding='same', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), model)\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(192, (3, 3), padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(128, (1, 1), padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Conv2D(256, (1, 1), padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(256, (1, 1), padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Conv2D(256, (1, 1), padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Conv2D(256, (1, 1), padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Conv2D(256, (1, 1), padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))# 4 times\n",
        "model.add(Conv2D(512, (1, 1), padding='same'))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(512, (1, 1), padding='same'))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "model.add(Conv2D(512, (1, 1), padding='same'))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "model.add(Conv2D(1024, (3, 3), strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(units=7*7*30))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-a69ecd2c39b7>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    Conv2D_BN_Leaky(64, (7, 7), strides=2, padding='same', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), model)\u001b[0m\n\u001b[0m                                                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viyBcqVFGGK1",
        "colab_type": "code",
        "outputId": "86a48140-1e37-47b1-efb5-2411cdecee94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "## Train\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "earlystop = EarlyStopping(patience=5)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.0001)\n",
        "EPOCHS=20\n",
        "BATCH_SIZE=15\n",
        "callbacks = [learning_rate_reduction]\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train,\n",
        "                    shuffle=True,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test)\n",
        "                    ,callbacks=callbacks)\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 7s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              102761472 \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 126,885,258\n",
            "Trainable params: 103,294,474\n",
            "Non-trainable params: 23,590,784\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 17939 samples, validate on 4485 samples\n",
            "Epoch 1/20\n",
            "17939/17939 [==============================] - 95s 5ms/step - loss: 0.8347 - acc: 0.7453 - val_loss: 0.1060 - val_acc: 0.9882\n",
            "Epoch 2/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.2441 - acc: 0.9404 - val_loss: 0.0478 - val_acc: 0.9946\n",
            "Epoch 3/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.1520 - acc: 0.9681 - val_loss: 0.0297 - val_acc: 0.9969\n",
            "Epoch 4/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.1068 - acc: 0.9792 - val_loss: 0.0217 - val_acc: 0.9967\n",
            "Epoch 5/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0837 - acc: 0.9841 - val_loss: 0.0174 - val_acc: 0.9973\n",
            "Epoch 6/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0675 - acc: 0.9877 - val_loss: 0.0153 - val_acc: 0.9975\n",
            "Epoch 7/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0574 - acc: 0.9897 - val_loss: 0.0131 - val_acc: 0.9971\n",
            "Epoch 8/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0541 - acc: 0.9910 - val_loss: 0.0117 - val_acc: 0.9975\n",
            "Epoch 9/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0454 - acc: 0.9931 - val_loss: 0.0104 - val_acc: 0.9975\n",
            "Epoch 10/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0393 - acc: 0.9941 - val_loss: 0.0096 - val_acc: 0.9982\n",
            "Epoch 11/20\n",
            "17939/17939 [==============================] - 83s 5ms/step - loss: 0.0351 - acc: 0.9944 - val_loss: 0.0087 - val_acc: 0.9982\n",
            "Epoch 12/20\n",
            "17939/17939 [==============================] - 81s 5ms/step - loss: 0.0313 - acc: 0.9952 - val_loss: 0.0081 - val_acc: 0.9978\n",
            "Epoch 13/20\n",
            "17939/17939 [==============================] - 80s 4ms/step - loss: 0.0310 - acc: 0.9948 - val_loss: 0.0074 - val_acc: 0.9982\n",
            "Epoch 14/20\n",
            "17939/17939 [==============================] - 80s 4ms/step - loss: 0.0296 - acc: 0.9950 - val_loss: 0.0079 - val_acc: 0.9982\n",
            "Epoch 15/20\n",
            "17939/17939 [==============================] - 80s 4ms/step - loss: 0.0252 - acc: 0.9965 - val_loss: 0.0069 - val_acc: 0.9982\n",
            "Epoch 16/20\n",
            "17939/17939 [==============================] - 80s 4ms/step - loss: 0.0223 - acc: 0.9968 - val_loss: 0.0066 - val_acc: 0.9982\n",
            "Epoch 17/20\n",
            "17939/17939 [==============================] - 80s 4ms/step - loss: 0.0214 - acc: 0.9974 - val_loss: 0.0063 - val_acc: 0.9987\n",
            "Epoch 18/20\n",
            "17939/17939 [==============================] - 80s 4ms/step - loss: 0.0204 - acc: 0.9972 - val_loss: 0.0064 - val_acc: 0.9982\n",
            "Epoch 19/20\n",
            "17939/17939 [==============================] - 80s 4ms/step - loss: 0.0186 - acc: 0.9980 - val_loss: 0.0059 - val_acc: 0.9984\n",
            "Epoch 20/20\n",
            "17939/17939 [==============================] - 80s 4ms/step - loss: 0.0185 - acc: 0.9971 - val_loss: 0.0058 - val_acc: 0.9984\n",
            "Test loss: 0.00581190100172275\n",
            "Test accuracy: 0.9984392419175028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuU_F56AITNa",
        "colab_type": "code",
        "outputId": "5f0d7cfb-2c16-43bc-96c3-e002c98b9389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.save('driver_detection_resnet_20_epoch.h5')\n",
        "shutil.copyfile('driver_detection_resnet_20_epoch.h5', DRIVE_PATH + 'driver_detection_resnet_20_epoch.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/colab/driver_detection_resnet_20_epoch.h5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ITS_NcmJv2",
        "colab_type": "code",
        "outputId": "bb2104cd-1f01-4dff-ed3b-7bcb5b475ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Copy prediction file to G-drive\n",
        "import shutil\n",
        "CATEGORY_PATH='tmp/predict' + str(index)\n",
        "if os.path.exists(CATEGORY_PATH):\n",
        "  shutil.rmtree(CATEGORY_PATH)\n",
        "#print(test_data.head())\n",
        "if not os.path.exists(CATEGORY_PATH):\n",
        "  os.mkdir(CATEGORY_PATH)\n",
        "  for i in range(10):\n",
        "    os.mkdir(\"%s/c%s\"% (CATEGORY_PATH,str(i)))\n",
        "\n",
        "test_data['category'] = np.argmax(predict_df, axis=1)\n",
        "for _, row in test_data.iterrows():\n",
        "  #print(row['category'])\n",
        "  #print(str(row['category']))\n",
        "  shutil.copyfile(TEST_DIRECTORY + \"/\" + row['filename'], CATEGORY_PATH + \"/\" + 'c' + str(row['category']) + \"/\" + row['filename'])\n",
        "\n",
        "ZIP_FILE_NAME='predict' + str(index)\n",
        "shutil.make_archive(ZIP_FILE_NAME, 'zip', CATEGORY_PATH)\n",
        "shutil.copyfile(ZIP_FILE_NAME +'.zip','/content/drive/My Drive/colab/' + ZIP_FILE_NAME + '.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/colab/predict9.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtk8tf_IBo7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}