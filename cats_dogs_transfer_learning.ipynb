{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_dogs_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cathay/cnn/blob/master/cats_dogs_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEGEvkaszifK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Import Google drive functions\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWQ3eGJHAqEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utilities to upload files\n",
        "def upload_files():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for k, v in uploaded.items():\n",
        "    open(k, 'wb').write(v)\n",
        "  return list(uploaded.keys())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdoNsTvtEHB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Authorize Google drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X7meTIJEpqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download train and test images\n",
        "download = drive.CreateFile({'id': '1EVPUykY4KwHvWL-umtLhJIfGhCFtHqn8'})\n",
        "download.GetContentFile('train.zip')\n",
        "download = drive.CreateFile({'id': '1l4vKliu1LB5Y65ZMvsSDrJiPG2mKvdqN'})\n",
        "download.GetContentFile('test1.zip')\n",
        "\n",
        "#Extract files\n",
        "zip_ref = zipfile.ZipFile('train.zip', 'r')\n",
        "zip_ref.extractall('tmp')\n",
        "zip_ref = zipfile.ZipFile('test1.zip', 'r')\n",
        "zip_ref.extractall('tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRt7YsKtFQvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_im_cv2(path, w, h):\n",
        "  img = cv2.imread(path)\n",
        "  resized = cv2.resize(img, (w,h), cv2.INTER_LINEAR) \n",
        "  return resized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIQDs4iSHXdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAININNG_DIRECTORY='tmp/train'\n",
        "IMAGE_WIDTH=224\n",
        "IMAGE_HEIGHT=224\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "\n",
        "df = pd.DataFrame({'filename': os.listdir(TRAININNG_DIRECTORY)})\n",
        "\n",
        "df['category'] = df['filename'].map(lambda file_name: file_name.split('.')[0])\n",
        "df['Y'] = df['category'].map(lambda x: np.array([0,1]) if x =='cat' else np.array([1,0]))\n",
        "df['X'] = df['filename'].map(lambda file: get_im_cv2(TRAININNG_DIRECTORY + \"/\" + file, IMAGE_WIDTH, IMAGE_HEIGHT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCrtEGBtBLFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d20646a5-6418-439b-a4b3-0cf61866f3f2"
      },
      "source": [
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "\n",
        "x_train = []\n",
        "x_test = []\n",
        "y_train = []\n",
        "y_test= []\n",
        "\n",
        "for item in train_df['X']:\n",
        "  x_train.append(item)\n",
        "\n",
        "for item in validate_df['X']:\n",
        "  x_test.append(item)\n",
        "\n",
        "for item in train_df['Y']:\n",
        "  y_train.append(item)\n",
        "\n",
        "for item in validate_df['Y']:\n",
        "  y_test.append(item)\n",
        "\n",
        "x_train = np.array(x_train, dtype=np.uint8)\n",
        "x_test = np.array(x_test, dtype=np.uint8)\n",
        "y_train = np.array(y_train, dtype=np.uint8)\n",
        "y_test = np.array(y_test, dtype=np.uint8)\n",
        "\n",
        "print(x_train[0].shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtLdBc-x0jJy",
        "colab_type": "code",
        "outputId": "2122990f-e7d2-4618-df4e-ae95dc279c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#build model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "#base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0001), metrics=['accuracy'])\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 40,937,794\n",
            "Trainable params: 26,220,034\n",
            "Non-trainable params: 14,717,760\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfxx5-EKwHlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkvg7sgz1nBq",
        "colab_type": "code",
        "outputId": "893a9d65-3506-4455-f730-05c680aaf566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "earlystop = EarlyStopping(patience=10)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.0001)\n",
        "EPOCHS=30\n",
        "BATCH_SIZE=15\n",
        "callbacks = [learning_rate_reduction]\n",
        "\n",
        "#x_train = np.expand_dims(y_train, axis=0)\n",
        "#_train = preprocess_input(x_train)\n",
        "print(x_train.shape)\n",
        "print(x_train[0].shape)\n",
        "history = model.fit(x_train, \n",
        "                    y_train,\n",
        "                    shuffle=True,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test)\n",
        "                    ,callbacks=callbacks)\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 224, 224, 3)\n",
            "(224, 224, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            " 9210/20000 [============>.................] - ETA: 42s - loss: 0.2912"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu4x8g_K2HSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot the loss\n",
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
        "ax1.set_xticks(np.arange(1, EPOCHS, 1))\n",
        "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
        "\n",
        "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "ax2.set_xticks(np.arange(1, EPOCHS, 1))\n",
        "\n",
        "legend = plt.legend(loc='best', shadow=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDpn0XD7EVfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_DIRECTORY = 'tmp/test1'\n",
        "test_data_frame = pd.DataFrame({'filename': os.listdir(TEST_DIRECTORY)})\n",
        "\n",
        "#df['category'] = df['filename'].map(lambda file_name: file_name.split('.')[0])\n",
        "#df['Y'] = df['category'].map(lambda x: np.array([1,0])if x !='cat' else np.array([0,1]))\n",
        "test_data_frame['X'] = test_data_frame['filename'].map(lambda file: get_im_cv2(TEST_DIRECTORY + \"/\" + file, IMAGE_WIDTH, IMAGE_HEIGHT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG074fpS3At2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_perf=[]\n",
        "for item in test_data_frame['X']:\n",
        "  x_perf.append(item)\n",
        "\n",
        "x_perf = np.array(x_perf, dtype=np.uint8)\n",
        "predict = model.predict(x_perf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPGcULu-GPcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(predict[0])\n",
        "print(predict[1])\n",
        "print(predict[2])\n",
        "test_data_frame['category'] = np.argmax(predict, axis=1)\n",
        "label_map = { 0:'dog', 1:'cat'}\n",
        "test_data_frame['animal'] = test_data_frame['category'].map(lambda x: label_map.get(x))\n",
        "test_data_frame.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6e-qFoy4Hna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Draw predictions with images\n",
        "from keras.preprocessing.image import load_img\n",
        "sample_test = test_data_frame.head(19)\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(12, 24))\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['category']\n",
        "    img = load_img(\"tmp/test1/\"+filename, target_size=IMAGE_SIZE)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}