{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_dogs_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cathay/cnn/blob/master/cats_dogs_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEGEvkaszifK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "2811df5a-5d2d-40c7-b499-7affc2c6f334"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Import Google drive functions\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWQ3eGJHAqEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utilities to upload files\n",
        "def upload_files():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for k, v in uploaded.items():\n",
        "    open(k, 'wb').write(v)\n",
        "  return list(uploaded.keys())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdoNsTvtEHB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Authorize Google drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X7meTIJEpqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download train and test images\n",
        "download = drive.CreateFile({'id': '1EVPUykY4KwHvWL-umtLhJIfGhCFtHqn8'})\n",
        "download.GetContentFile('train.zip')\n",
        "download = drive.CreateFile({'id': '1l4vKliu1LB5Y65ZMvsSDrJiPG2mKvdqN'})\n",
        "download.GetContentFile('test1.zip')\n",
        "\n",
        "#Extract files\n",
        "zip_ref = zipfile.ZipFile('train.zip', 'r')\n",
        "zip_ref.extractall('tmp')\n",
        "zip_ref = zipfile.ZipFile('test1.zip', 'r')\n",
        "zip_ref.extractall('tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRt7YsKtFQvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_im_cv2(path, w, h):\n",
        "  img = cv2.imread(path)\n",
        "  resized = cv2.resize(img, (w,h), cv2.INTER_LINEAR) \n",
        "  return resized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIQDs4iSHXdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAININNG_DIRECTORY='tmp/train'\n",
        "IMAGE_WIDTH=224\n",
        "IMAGE_HEIGHT=224\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "\n",
        "df = pd.DataFrame({'filename': os.listdir(TRAININNG_DIRECTORY)})\n",
        "\n",
        "df['category'] = df['filename'].map(lambda file_name: file_name.split('.')[0])\n",
        "df['Y'] = df['category'].map(lambda x: np.array([0,1]) if x =='cat' else np.array([1,0]))\n",
        "df['X'] = df['filename'].map(lambda file: get_im_cv2(TRAININNG_DIRECTORY + \"/\" + file, IMAGE_WIDTH, IMAGE_HEIGHT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCrtEGBtBLFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "\n",
        "x_train = []\n",
        "x_test = []\n",
        "y_train = []\n",
        "y_test= []\n",
        "\n",
        "for item in train_df['X']:\n",
        "  x_train.append(item)\n",
        "\n",
        "for item in validate_df['X']:\n",
        "  x_test.append(item)\n",
        "\n",
        "for item in train_df['Y']:\n",
        "  y_train.append(item)\n",
        "\n",
        "for item in validate_df['Y']:\n",
        "  y_test.append(item)\n",
        "\n",
        "x_train = np.array(x_train, dtype=np.uint8)\n",
        "x_test = np.array(x_test, dtype=np.uint8)\n",
        "y_train = np.array(y_train, dtype=np.uint8)\n",
        "y_test = np.array(y_test, dtype=np.uint8)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtLdBc-x0jJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "#base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0001), metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfxx5-EKwHlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build Alex Net\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "\n",
        "# Here, we use a larger 11 x 11 window to capture objects. At the same time,\n",
        "# we use a stride of 4 to greatly reduce the height and width of the output.\n",
        "# Here, the number of output channels is much larger than that in LeNet\n",
        "model = Sequential()\n",
        "model.add(Conv2D(96, kernel_size=11, strides=4, activation='relu'),\n",
        "          MaxPooling2D(pool_size=3, strides=2),\n",
        "        # Make the convolution window smaller, set padding to 2 for consistent\n",
        "        # height and width across the input and output, and increase the\n",
        "        # number of output channels\n",
        "          Conv2D(256, kernel_size=5, padding=2, activation='relu'),\n",
        "          MaxPooling2D(pool_size=3, strides=2),\n",
        "        # Use three successive convolutional layers and a smaller convolution\n",
        "        # window. Except for the final convolutional layer, the number of\n",
        "        # output channels is further increased. Pooling layers are not used to\n",
        "        # reduce the height and width of input after the first two\n",
        "        # convolutional layers\n",
        "          Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
        "          Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n",
        "          Conv2D(256, kernel_size=3, padding=1, activation='relu'),\n",
        "          MaxPooling2D(pool_size=3, strides=2),\n",
        "        # Here, the number of outputs of the fully connected layer is several\n",
        "        # times larger than that in LeNet. Use the dropout layer to mitigate\n",
        "        # overfitting\n",
        "          Dense(4096, activation=\"relu\"), nn.Dropout(0.5),\n",
        "          Dense(4096, activation=\"relu\"), nn.Dropout(0.5),\n",
        "        # Output layer. Since we are using Fashion-MNIST, the number of\n",
        "        # classes is 10, instead of 1000 as in the paper\n",
        "          Dense(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkvg7sgz1nBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "earlystop = EarlyStopping(patience=5)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.0001)\n",
        "EPOCHS=30\n",
        "BATCH_SIZE=15\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train,\n",
        "                    shuffle=True,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test)\n",
        "                    ,callbacks=callbacks)\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu4x8g_K2HSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot the loss\n",
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
        "ax1.set_xticks(np.arange(1, EPOCHS, 1))\n",
        "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
        "\n",
        "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "ax2.set_xticks(np.arange(1, EPOCHS, 1))\n",
        "\n",
        "legend = plt.legend(loc='best', shadow=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDpn0XD7EVfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_DIRECTORY = 'tmp/test1'\n",
        "test_data_frame = pd.DataFrame({'filename': os.listdir(TEST_DIRECTORY)})\n",
        "\n",
        "#df['category'] = df['filename'].map(lambda file_name: file_name.split('.')[0])\n",
        "#df['Y'] = df['category'].map(lambda x: np.array([1,0])if x !='cat' else np.array([0,1]))\n",
        "test_data_frame['X'] = test_data_frame['filename'].map(lambda file: get_im_cv2(TEST_DIRECTORY + \"/\" + file, IMAGE_WIDTH, IMAGE_HEIGHT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG074fpS3At2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_perf=[]\n",
        "for item in test_data_frame['X']:\n",
        "  x_perf.append(item)\n",
        "\n",
        "x_perf = np.array(x_perf, dtype=np.uint8)\n",
        "predict = model.predict(x_perf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPGcULu-GPcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(predict[0])\n",
        "print(predict[1])\n",
        "print(predict[2])\n",
        "test_data_frame['category'] = np.argmax(predict, axis=1)\n",
        "label_map = { 0:'dog', 1:'cat'}\n",
        "test_data_frame['animal'] = test_data_frame['category'].map(lambda x: label_map.get(x))\n",
        "test_data_frame.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6e-qFoy4Hna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Draw predictions with images\n",
        "from keras.preprocessing.image import load_img\n",
        "sample_test = test_data_frame.head(19)\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(12, 24))\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['category']\n",
        "    img = load_img(\"tmp/test1/\"+filename, target_size=IMAGE_SIZE)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}