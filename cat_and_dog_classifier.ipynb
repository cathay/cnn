{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cathay/cnn/blob/master/cat_and_dog_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEGEvkaszifK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Import Google drive functions\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWQ3eGJHAqEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utilities to upload files\n",
        "def upload_files():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for k, v in uploaded.items():\n",
        "    open(k, 'wb').write(v)\n",
        "  return list(uploaded.keys())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdoNsTvtEHB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Authorize Google drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X7meTIJEpqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download train and test images\n",
        "download = drive.CreateFile({'id': '1EVPUykY4KwHvWL-umtLhJIfGhCFtHqn8'})\n",
        "download.GetContentFile('train.zip')\n",
        "download = drive.CreateFile({'id': '1l4vKliu1LB5Y65ZMvsSDrJiPG2mKvdqN'})\n",
        "download.GetContentFile('tests.zip')\n",
        "\n",
        "#Extract files\n",
        "zip_ref = zipfile.ZipFile('train.zip', 'r')\n",
        "zip_ref.extractall('tmp')\n",
        "zip_ref = zipfile.ZipFile('tests.zip', 'r')\n",
        "zip_ref.extractall('tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRt7YsKtFQvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_im_cv2(path, w, h):\n",
        "  img = cv2.imread(path)\n",
        "  resized = cv2.resize(img, (w,h), cv2.INTER_LINEAR) \n",
        "  return resized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIQDs4iSHXdX",
        "colab_type": "code",
        "outputId": "a7fe662e-e69a-4d71-eaba-532f808f1c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "TRAININNG_DIRECTORY='tmp/train'\n",
        "IMAGE_WIDTH=128\n",
        "IMAGE_HEIGHT=128\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "\n",
        "df = pd.DataFrame({'file': os.listdir(TRAININNG_DIRECTORY)})\n",
        "\n",
        "df['animal'] = df['file'].map(lambda file_name: file_name.split('.')[0])\n",
        "df['Y'] = df['animal'].map(lambda x: np.array([1,0]).transpose() if x !='cat' else np.array([0,1]).transpose())\n",
        "df['X'] = df['file'].map(lambda file: get_im_cv2(TRAININNG_DIRECTORY + \"/\" + file, IMAGE_WIDTH, IMAGE_HEIGHT))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "12500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>animal</th>\n",
              "      <th>Y</th>\n",
              "      <th>X</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cat.5721.jpg</td>\n",
              "      <td>cat</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[[[152, 174, 209], [152, 174, 209], [152, 174,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cat.12084.jpg</td>\n",
              "      <td>cat</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[[[96, 93, 94], [138, 117, 99], [144, 131, 126...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dog.11124.jpg</td>\n",
              "      <td>dog</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[[[27, 49, 45], [51, 77, 73], [22, 47, 43], [4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dog.5092.jpg</td>\n",
              "      <td>dog</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[[[158, 180, 197], [154, 176, 193], [153, 174,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cat.7605.jpg</td>\n",
              "      <td>cat</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[[[101, 152, 185], [100, 151, 184], [104, 155,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            file  ...                                                  X\n",
              "0   cat.5721.jpg  ...  [[[152, 174, 209], [152, 174, 209], [152, 174,...\n",
              "1  cat.12084.jpg  ...  [[[96, 93, 94], [138, 117, 99], [144, 131, 126...\n",
              "2  dog.11124.jpg  ...  [[[27, 49, 45], [51, 77, 73], [22, 47, 43], [4...\n",
              "3   dog.5092.jpg  ...  [[[158, 180, 197], [154, 176, 193], [153, 174,...\n",
              "4   cat.7605.jpg  ...  [[[101, 152, 185], [100, 151, 184], [104, 155,...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCrtEGBtBLFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_numpy, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "\n",
        "x_train = []\n",
        "x_test = []\n",
        "y_train = []\n",
        "y_test= []\n",
        "\n",
        "for item in train_df['X']:\n",
        "  x_train.append(item)\n",
        "\n",
        "for item in validate_df['X']:\n",
        "  x_test.append(item)\n",
        "\n",
        "for item in train_df['Y']:\n",
        "  y_train.append(item)\n",
        "\n",
        "for item in validate_df['Y']:\n",
        "  y_test.append(item)\n",
        "\n",
        "x_train = np.array(x_train, dtype=np.uint8)\n",
        "x_test = np.array(x_test, dtype=np.uint8)\n",
        "y_train = np.array(y_train, dtype=np.uint8)\n",
        "y_test = np.array(y_test, dtype=np.uint8)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtLdBc-x0jJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkvg7sgz1nBq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "65f69565-24e8-4ff6-967b-fe8a807c2d5a"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "earlystop = EarlyStopping(patience=10)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "EPOCHS=10\n",
        "BATCH_SIZE=128\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/3\n",
            "20000/20000 [==============================] - 1293s 65ms/step - loss: 0.6203 - acc: 0.7088 - val_loss: 0.4883 - val_acc: 0.7754\n",
            "Epoch 2/3\n",
            "20000/20000 [==============================] - 1290s 65ms/step - loss: 0.4258 - acc: 0.8067 - val_loss: 0.5456 - val_acc: 0.7604\n",
            "Epoch 3/3\n",
            "14145/20000 [====================>.........] - ETA: 5:49 - loss: 0.3424 - acc: 0.8566"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-7ea8a8c987cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu4x8g_K2HSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "outputId": "6c22f040-bba1-4fe9-b90a-bf0665759b42"
      },
      "source": [
        "#Plot the loss\n",
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
        "ax1.set_xticks(np.arange(1, epochs, 1))\n",
        "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
        "\n",
        "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "ax2.set_xticks(np.arange(1, epochs, 1))\n",
        "\n",
        "legend = plt.legend(loc='best', shadow=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-b024fe8d338c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAKvCAYAAABzr+mpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMBAKAMAwOD/A9J6Q6FGs0cPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}